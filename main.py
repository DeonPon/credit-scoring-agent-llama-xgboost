import os
import json
import asyncio
import sqlite3
import pandas as pd
import xgboost as xgb
from fastapi import FastAPI
from dotenv import load_dotenv
from groq import Groq
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from aiogram.utils.keyboard import InlineKeyboardBuilder
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode

load_dotenv()
app = FastAPI()

# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ DefaultBotProperties –¥–ª—è —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ –∑ –Ω–æ–≤–∏–º aiogram
bot = Bot(
    token=os.getenv("TELEGRAM_BOT_TOKEN"),
    default=DefaultBotProperties(parse_mode=ParseMode.HTML)
)
dp = Dispatcher()
client = Groq(api_key=os.getenv("GROQ_API_KEY"))

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ XGBoost
model = xgb.XGBClassifier()
model.load_model("loan_model.json")


# --- –†–û–ë–û–¢–ê –ó –ë–î ---
def init_db():
    conn = sqlite3.connect("bot_memory.db")
    cursor = conn.cursor()
    cursor.execute("CREATE TABLE IF NOT EXISTS history (user_id INTEGER PRIMARY KEY, data TEXT)")
    conn.commit()
    conn.close()


def get_user_history(user_id):
    conn = sqlite3.connect("bot_memory.db")
    cursor = conn.cursor()
    cursor.execute("SELECT data FROM history WHERE user_id = ?", (user_id,))
    row = cursor.fetchone()
    conn.close()
    return json.loads(row[0]) if row else []


def save_user_history(user_id, history):
    conn = sqlite3.connect("bot_memory.db")
    cursor = conn.cursor()
    cursor.execute("INSERT OR REPLACE INTO history VALUES (?, ?)", (user_id, json.dumps(history)))
    conn.commit()
    conn.close()


init_db()


# --- –ö–ù–û–ü–ö–ê ---
def get_clear_kb():
    builder = InlineKeyboardBuilder()
    builder.row(types.InlineKeyboardButton(text="üßπ –û—á–∏—Å—Ç–∏—Ç–∏ –¥—ñ–∞–ª–æ–≥", callback_data="clear_history"))
    return builder.as_markup()


# --- –ü–†–û–ì–ù–û–ó ---
def get_prediction(data):
    df = pd.DataFrame([data])
    df = df[['age', 'income', 'loan_amount', 'credit_score']]
    prob = model.predict_proba(df)[0][1]
    status = "–°—Ö–≤–∞–ª–µ–Ω–æ" if model.predict(df)[0] == 1 else "–í—ñ–¥—Ö–∏–ª–µ–Ω–æ"
    return status, f"{round(float(prob) * 100, 2)}%"


# --- –û–ë–†–û–ë–ù–ò–ö–ò ---
@dp.message(Command("start"))
async def start(message: types.Message):
    save_user_history(message.from_user.id, [])
    await message.answer(
        "<b>–í—ñ—Ç–∞—é! –Ø –≤–∞—à –∫—Ä–µ–¥–∏—Ç–Ω–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç.</b> üè¶\n\n"
        "–ù–∞–ø–∏—à—ñ—Ç—å –º–µ–Ω—ñ –≤–∞—à –≤—ñ–∫, –¥–æ—Ö—ñ–¥ –∑–∞ –º—ñ—Å—è—Ü—å, –±–∞–∂–∞–Ω—É —Å—É–º—É –∫—Ä–µ–¥–∏—Ç—É —Ç–∞ –∫—Ä–µ–¥–∏—Ç–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥.",
        reply_markup=get_clear_kb()
    )


@dp.callback_query(F.data == "clear_history")
async def clear_history_handler(callback: types.CallbackQuery):  # –ü—Ä–∞–≤–∏–ª—å–Ω–∞ –Ω–∞–∑–≤–∞ —Ç–∏–ø—É
    save_user_history(callback.from_user.id, [])
    await callback.answer("–î–∞–Ω—ñ –≤–∏–¥–∞–ª–µ–Ω–æ")
    await callback.message.answer("–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω–æ. –Ø –≥–æ—Ç–æ–≤–∏–π –¥–æ –Ω–æ–≤–∏—Ö —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—ñ–≤!", reply_markup=get_clear_kb())


@dp.message()
async def handle_message(message: types.Message):
    user_id = message.from_user.id
    history = get_user_history(user_id)
    history.append({"role": "user", "content": message.text})

    try:
        # 1. –í–∏—Ç—è–≥—É—î–º–æ –¥–∞–Ω—ñ (–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ 70b –º–æ–¥–µ–ª—å –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç—ñ)
        extract = client.chat.completions.create(
            messages=[{"role": "system",
                       "content": "Extract: age, income, loan_amount, credit_score. Return ONLY JSON. If missing, use null."}] + history,
            model="llama-3.3-70b-versatile",
            response_format={"type": "json_object"}
        )
        data = json.loads(extract.choices[0].message.content)

        required = ["age", "income", "loan_amount", "credit_score"]
        missing = [f for f in required if not data.get(f)]

        if not missing:
            # 2. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫
            status, prob = get_prediction(data)

            # –°–£–í–û–†–ò–ô –ü–†–û–ú–ü–¢ –î–õ–Ø –í–Ü–î–ü–û–í–Ü–î–Ü (–∑–∞–ø–æ–±—ñ–≥–∞—î–º–æ –≥–∞–ª—é—Ü–∏–Ω–∞—Ü—ñ—è–º)
            prompt = (f"–¢–∏ –º–µ–Ω–µ–¥–∂–µ—Ä —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–≥–æ –±–∞–Ω–∫—É. –ö–ª—ñ—î–Ω—Ç—É {status} –∫—Ä–µ–¥–∏—Ç –∑ —ñ–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—é {prob}. "
                      "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–µ, –≤–≤—ñ—á–ª–∏–≤–µ —Ä—ñ—à–µ–Ω–Ω—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é. "
                      "–ù–ï –≤–∏–≥–∞–¥—É–π –ø—Ä–æ —á–µ—Å—å–∫—ñ —Ä–∏–Ω–∫–∏, –¥–∏—Ç–∏–Ω—Å—Ç–≤–æ —á–∏ —ñ–Ω–≤–µ—Å—Ç–∏—Ü—ñ—ó. "
                      "–ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¥—É–∂–∫–∏ [] –∞–±–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∏. –ü–∏—à–∏ —è–∫ –ª—é–¥–∏–Ω–∞.")

            res = client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model="llama-3.3-70b-versatile"
            )
            bot_answer = res.choices[0].message.content
        else:
            # 3. –ó–∞–ø–∏—Ç –≤—ñ–¥—Å—É—Ç–Ω—ñ—Ö –¥–∞–Ω–∏—Ö
            prompt = (f"–ù–∞–º –±—Ä–∞–∫—É—î: {missing}. –ü–æ–ø—Ä–æ—Å–∏ –∫–ª—ñ—î–Ω—Ç–∞ –Ω–∞–¥–∞—Ç–∏ —Ü—ñ –¥–∞–Ω—ñ –ø—Ä–∏—Ä–æ–¥–Ω–æ—é —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é. "
                      "–ë—É–¥—å –ª–∞–∫–æ–Ω—ñ—á–Ω–∏–º. –ñ–æ–¥–Ω–∏—Ö —Å–ø–∏—Å–∫—ñ–≤ –∑—ñ –∑—ñ—Ä–æ—á–∫–∞–º–∏ **.")
            res = client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model="llama-3.3-70b-versatile"
            )
            bot_answer = res.choices[0].message.content

        history.append({"role": "assistant", "content": bot_answer})
        save_user_history(user_id, history[-6:])
        await message.answer(bot_answer, reply_markup=get_clear_kb())

    except Exception as e:
        print(f"Error: {e}")
        await message.answer("–í–∏–±–∞—á—Ç–µ, —Ç–µ—Ö–Ω—ñ—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞. –°–ø—Ä–æ–±—É–π—Ç–µ —É—Ç–æ—á–Ω–∏—Ç–∏ –¥–∞–Ω—ñ.", reply_markup=get_clear_kb())


@app.on_event("startup")
async def on_startup():
    asyncio.create_task(dp.start_polling(bot))


@app.get("/")
def home(): return {"status": "online"}